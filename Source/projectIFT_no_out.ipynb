{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot validations curve for each model. Training model and get an average accuracy / matrix confusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "import Model\n",
    "import Utils\n",
    "import DataManager as DM  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the database :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading Database...\")\n",
    "dm = DM.DataManager(150, 50, normalisation=False)\n",
    "x_train, t_train, x_test, t_test = dm.generer_donnees()\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = Utils.ModelAnalyzer()\n",
    "x = x_train\n",
    "t = t_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of training to do per model\n",
    "k = 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters of the model Perceptron (model1) :\n",
    "alpha(reg) : 10^-3 to 10^3 log scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"model Perceptron\")\n",
    "\n",
    "model1 = Model.Perceptron(reg_penalty='l2', reg=0.001)\n",
    "para_range = np.logspace(-3, 3, 7)\n",
    "titleVC = \"Validation curves : Perceptron\"\n",
    "plt, test_scores_alpha_means = analyzer.plotValidationCurve(model1.model, x, t, title=titleVC, param_name=\"alpha\",param_range=para_range, verbose=True, scaling=\"log\")\n",
    "    \n",
    "bestInd = np.argmax(test_scores_alpha_means)\n",
    "print(bestInd)\n",
    "    \n",
    "model1Alpha = para_range[bestInd]\n",
    "print(\"Best alpha for the Perceptron is \", model1Alpha)\n",
    "plt.rcParams['figure.figsize'] = [12.0, 10.0]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training of the model Perceptron  :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters of the Perceptron model \n",
    "hyp1Mod1 = model1Alpha\n",
    "print(\"Training with the parameter (alpha) :\", hyp1Mod1)\n",
    "\n",
    "bestAccuMod1 = 0\n",
    "bestConfMaxMod1 = 0\n",
    "bestModel1 =  0\n",
    "\n",
    "# Training\n",
    "accu = np.zeros(k)\n",
    "\n",
    "for i in range(k):\n",
    "    print(\"Training \", i + 1, \" Perceptron model\")\n",
    "    md1 = Model.Perceptron(reg_penalty='l2', reg=hyp1Mod1, random_state=i)\n",
    "    md1.train(x_train, t_train)\n",
    "    predictions_test = np.array([md1.prediction(x) for x in x_test])\n",
    "\n",
    "    accu[i] = analyzer.accuracy(t_test, predictions_test)\n",
    "    \n",
    "    if accu[i] > bestAccuMod1:\n",
    "        bestAccuMod1 = accu[i]\n",
    "        bestModel1 = md1\n",
    "        bestConfMaxMod1 = analyzer.confusionMatrix(t_test, predictions_test)\n",
    "\n",
    "# Average accuracy and  std accuracy\n",
    "print(accu)\n",
    "accuMean = np.mean(accu)\n",
    "accuStd = np.std(accu)\n",
    "print(\"The average accuracy is : \", accuMean)\n",
    "print(\"The std accuracu is : \", accuStd)\n",
    "print(\"The best accuracy is : \", bestAccuMod1)\n",
    "print(\"The confusion matrix of the best model : \")\n",
    "print(bestConfMaxMod1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hidden layer to test : \n",
    "model 2a(200,) model2b (200,200,200) model 2c(200,400,600) model2d (600,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters of the multilayer Perceptron(model 2a) :\n",
    "alpha(reg) : 10^-3 to 10^3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"validation curve model Multilayer Perceptron \")\n",
    "\n",
    "list_tuple = [(200,), (200,200,200), (200,400,600), (600,)]\n",
    "z = 0\n",
    "model2Alpha = np.zeros(4)\n",
    "print(model2Alpha)\n",
    "for specific_tuple in list_tuple:\n",
    "\n",
    "    model2 = Model.MLPerceptron(hidden_layer_sizes=specific_tuple, activation='relu', reg=0.001)\n",
    "    para_range = np.logspace(-3, 3, 7)\n",
    "    titleVC = \"Validation curves : Multilayer Perceptron with \" + str(specific_tuple)\n",
    "    plt, test_scores_mlp_alpha_means = analyzer.plotValidationCurve(model2.model, x, t, title=titleVC, param_name=\"alpha\",param_range=para_range, verbose=True, scaling=\"log\")\n",
    "    \n",
    "    bestInd = np.argmax(test_scores_mlp_alpha_means)\n",
    "    print(bestInd)\n",
    "    \n",
    "    model2Alpha[z] = para_range[bestInd]\n",
    "    print(\"Best alpha for the Multilayer Perceptron with \", specific_tuple, \" is \", model2Alpha[z])\n",
    "    \n",
    "    plt.show()\n",
    "    z = z + 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training of the model multilayer Perceptron (model 2a) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "list_tuple = [(200,), (200,200,200), (200,400,600), (600,)]\n",
    "z = 0\n",
    "bestModel2 = [Model.MLPerceptron(hidden_layer_sizes=1), Model.MLPerceptron(hidden_layer_sizes=1), Model.MLPerceptron(hidden_layer_sizes=1), Model.MLPerceptron(hidden_layer_sizes=1) ]\n",
    "\n",
    "for specific_tuple in list_tuple:\n",
    "    # Set hyperparameters of the multilayer Perceptron (model2a)\n",
    "    hyp1Mod2 = model2Alpha[z]\n",
    "    print(\"Training with the parameter (alpha) :\", hyp1Mod2)\n",
    "\n",
    "    # Training\n",
    "    accu = np.zeros(k)\n",
    "\n",
    "    for i in range(k):\n",
    "        bestAccuMod2 = 0\n",
    "        bestConfMaxMod2 = 0\n",
    "        bestModel2 =  0\n",
    "        print(\"Training \", i+1, \" multi-layer Perceptron with \", str(specific_tuple) )\n",
    "        md2 = Model.MLPerceptron(hidden_layer_sizes=specific_tuple, activation='relu', reg=hyp1Mod2, random_state=i) \n",
    "        md2.train(x_train, t_train)\n",
    "        predictions_test = np.array([md2.prediction(x) for x in x_test])\n",
    "\n",
    "        accu[i] = analyzer.accuracy(t_test, predictions_test)\n",
    "    \n",
    "        if accu[i] > bestAccuMod2:\n",
    "            bestAccuMod2 = accu[i]\n",
    "            if z == 0:\n",
    "                bestModel2a = md2\n",
    "            if z == 1:\n",
    "                bestModel2b = md2\n",
    "            if z == 2:\n",
    "                bestModel2c = md2\n",
    "            if z == 3:\n",
    "                bestModel2d = md2\n",
    "            bestConfMaxMod2 = analyzer.confusionMatrix(t_test, predictions_test)\n",
    "\n",
    "    # Average accuracy and  std accuracy\n",
    "    print(accu)\n",
    "    accuMean = np.mean(accu)\n",
    "    accuStd = np.std(accu)\n",
    "    print(\"The average accuracy is : \", accuMean)\n",
    "    print(\"The std accuracu is : \", accuStd)\n",
    "    print(\"The best accuracy is : \", bestAccuMod2)\n",
    "    print(\"The confusion matrix of the best model : \")\n",
    "    print(bestConfMaxMod2)\n",
    "    z = z+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rbf ou poly ??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters of the model SVM(model 3)(rbf) :\n",
    " C : 10^-3 to 10^3 log scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bestCMod3 = 1\n",
    "\n",
    "model3 = Model.ModelSVM(gamma=\"auto\",  kernel=\"rbf\")\n",
    "para_range = np.logspace(-3, 3, 7)\n",
    "titleVC = \"Validation curves : SVM with rbf \"\n",
    "plt, test_scores_deg_means = analyzer.plotValidationCurve(model3.model, x, t, title=titleVC, param_name=\"C\",param_range=para_range, verbose=True, scaling=\"log\")\n",
    "    \n",
    "bestInd = np.argmax(test_scores_deg_means)\n",
    "print(bestInd)\n",
    "    \n",
    "model3Reg = para_range[bestInd]\n",
    "print(\"Best c is : \",model3Reg)\n",
    "    \n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training of the model SVM (model 3) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters of the SVM model\n",
    "hyp2Mod3 = bestCMod3\n",
    "print(\"Training with the parameters (C) :\", hyp2Mod3)\n",
    "\n",
    "bestAccuMod3 = 0\n",
    "bestConfMaxMod3 = 0\n",
    "bestModel3 =  0\n",
    "\n",
    "# Training\n",
    "accu = np.zeros(k)\n",
    "\n",
    "for i in range(k):\n",
    "    print(\"Training \", i + 1, \" model SVM with rbf...\")\n",
    "    md3 = Model.ModelSVM(gamma=\"auto\",  kernel=\"rbf\", reg=hyp2Mod3, random_state=i)\n",
    "    md3.train(x_train, t_train)\n",
    "    predictions_test = np.array([md3.prediction(x) for x in x_test])\n",
    "\n",
    "    accu[i] = analyzer.accuracy(t_test, predictions_test)\n",
    "    \n",
    "    if accu[i] > bestAccuMod3:\n",
    "        bestAccuMod3 = accu[i]\n",
    "        bestModel3 = md3\n",
    "        bestConfMaxMod3 = analyzer.confusionMatrix(t_test, predictions_test)\n",
    "\n",
    "\n",
    "# Average accuracy and  std accuracy\n",
    "print(accu)\n",
    "accuMean = np.mean(accu)\n",
    "accuStd = np.std(accu)\n",
    "print(\"The average accuracy is : \", accuMean)\n",
    "print(\"The std accuracu is : \", accuStd)\n",
    "print(\"The best accuracy is : \", bestAccuMod3)\n",
    "print(\"The confusion matrix of the best model : \")\n",
    "print(bestConfMaxMod3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters of the model data tree classifier (model 4) : criterion= 'gini' or 'entropy' and max depth = 2 to 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestCritMod4 = 'gini'\n",
    "bestMaxDepthMod4 = 2\n",
    "bestTestScore = float('inf')\n",
    "dicCriteria = ['gini', 'entropy']\n",
    "\n",
    "for cri in dicCriteria:\n",
    "    para_range = np.linspace(2, 40, 39)\n",
    "    titleVC = \"Validation curves : Model Data tree classifier with criterion : \" + cri\n",
    "    model4 = Model.ModelDecisionTree()\n",
    "    plt, test_scores_means_md = analyzer.plotValidationCurve(model4.model, x, t, title=titleVC, param_name=\"max_depth\",param_range=para_range, verbose=True, scaling=\"lin\")\n",
    "    \n",
    "    bestInd = np.argmax(test_scores_means_md)\n",
    "    print(bestInd)\n",
    "    model4Maxdepth = para_range[bestInd]\n",
    "    \n",
    "    print(\"Best maxdepth with criterion \", cri ,\" is : \",model4Maxdepth)\n",
    "    plt.show()    \n",
    "    \n",
    "    if test_scores_means_md[bestInd] < bestTestScore:\n",
    "        bestTestScore = test_scores_means_md[bestInd]\n",
    "        bestCritMod4 = cri\n",
    "        bestMaxDepthMod4 = model4Maxdepth\n",
    "        \n",
    "print(\"The best parameter are (criterion, max_depth) :\", bestCritMod4, bestMaxDepthMod4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training of the model Data tree classifier :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters of the model data tree classifier\n",
    "hyp1Mod4 = bestCritMod4\n",
    "hyp2Mod4 = bestMaxDepthMod4\n",
    "\n",
    "bestAccuMod4 = 0\n",
    "bestConfMaxMod4 = 0\n",
    "bestModel4 =  0\n",
    "\n",
    "# Training \n",
    "accu = np.zeros(k)\n",
    "\n",
    "for i in range(k):\n",
    "    print(\"Training \", i + 1, \" model data tree classifier...\")\n",
    "    md4 = Model.ModelDecisionTree(max_depth=hyp2Mod4, criterion=hyp1Mod4, random_state=i)\n",
    "    md4.train(x_train, t_train)\n",
    "    predictions_test = np.array([md4.prediction(x.reshape(1, -1)) for x in x_test])\n",
    "\n",
    "    accu[i] = analyzer.accuracy(t_test, predictions_test)\n",
    "\n",
    "    if accu[i] > bestAccuMod4:\n",
    "        bestAccuMod4 = accu[i]\n",
    "        bestModel4 = md4\n",
    "        bestConfMaxMod4 = analyzer.confusionMatrix(t_test, predictions_test)\n",
    "\n",
    "    \n",
    "# Average accuracy and  std accuracy\n",
    "print(accu)\n",
    "accuMean = np.mean(accu)\n",
    "accuStd = np.std(accu)\n",
    "print(\"The average accuracy is : \", accuMean)\n",
    "print(\"The std accuracu is : \", accuStd)\n",
    "print(\"The best accuracy is : \", bestAccuMod4)\n",
    "print(\"The confusion matrix of the best model : \")\n",
    "print(bestConfMaxMod4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters of the Logistic Regression (Model 5) : C : 10^-3 to 10^3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Validation curve Logistic Regression (model 5)\")\n",
    "\n",
    "model5 = Model.LogisticRegression(reg_penalty='l2', reg_inv=1.0)\n",
    "para_range = np.logspace(-3, 3, 7)\n",
    "titleVC = \"Validation curves : Logistic Regression\"\n",
    "plt, test_scores_C_means = analyzer.plotValidationCurve(model5.model, x, t, title=titleVC, param_name=\"C\",param_range=para_range, verbose=True, scaling=\"log\")\n",
    "\n",
    "bestInd = np.argmax(test_scores_C_means)\n",
    "print(bestInd)\n",
    "    \n",
    "model5C = para_range[bestInd]\n",
    "print(\"Best C for the logistic Regression is \", model5C)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training of the Logistic Regression (Model 5) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters of the Logistic Regression (Model 5)\n",
    "hyp1Mod5 = model5C\n",
    "\n",
    "bestAccuMod5 = 0\n",
    "bestConfMaxMod5 = 0\n",
    "bestModel5 =  0\n",
    "\n",
    "#Training\n",
    "accu = np.zeros(k)\n",
    "\n",
    "for i in range(k):\n",
    "    print(\"Training \", i + 1, \" model Logistic Regression...\")\n",
    "    md5 = Model.LogisticRegression(reg_penalty='l2', reg_inv=hyp1Mod5, random_state=i)\n",
    "    md5.train(x_train, t_train)\n",
    "    predictions_test = np.array([md5.prediction(x) for x in x_test])\n",
    "\n",
    "    accu[i] = analyzer.accuracy(t_test, predictions_test)\n",
    "    if accu[i] > bestAccuMod5:\n",
    "        bestAccuMod5 = accu[i]\n",
    "        bestModel5 = md5\n",
    "        bestConfMaxMod5 = analyzer.confusionMatrix(t_test, predictions_test)\n",
    "\n",
    "\n",
    "# Average accuracy and  std accuracy\n",
    "print(accu)\n",
    "accuMean = np.mean(accu)\n",
    "accuStd = np.std(accu)\n",
    "print(\"The average accuracy is : \", accuMean)\n",
    "print(\"The std accuracu is : \", accuStd)\n",
    "print(\"The best accuracy is : \", bestAccuMod5)\n",
    "print(\"The confusion matrix of the best model : \")\n",
    "print(bestConfMaxMod5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training of the model Bagging (model 6) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up base model\n",
    "\n",
    "base_model = 'Perceptron'\n",
    "number_model = 50\n",
    "bestAccuMod6 = 0\n",
    "bestConfMaxMod6 = 0\n",
    "bestModel6 =  0\n",
    "\n",
    "# Training \n",
    "accu = np.zeros(k)\n",
    "\n",
    "for j in range(k):\n",
    "    print(\"Training \", j+1, \" Bagging model...\" )\n",
    "    md6 = Model.Bagging(base_model=base_model, number_model=number_model, reg_penalty='l2', reg=hyp1Mod1,random_state=i)\n",
    "    md6.train(x_train, t_train)\n",
    "    predictions_test = np.array([md6.prediction(x) for x in x_test])\n",
    "\n",
    "    accu[j] = analyzer.accuracy(t_test, predictions_test)\n",
    "    if accu[j] > bestAccuMod6:\n",
    "        bestAccuMod6 = accu[j]\n",
    "        bestModel6 = md6\n",
    "        bestConfMaxMod6 = analyzer.confusionMatrix(t_test, predictions_test)\n",
    "    \n",
    "# Average accuracy and  std accuracy\n",
    "print(accu)\n",
    "accuMean = np.mean(accu)\n",
    "accuStd = np.std(accu)\n",
    "print(\"The average accuracy is : \", accuMean)\n",
    "print(\"The std accuracu is : \", accuStd)\n",
    "print(\"The best accuracy is : \", bestAccuMod6)\n",
    "print(\"The confusion matrix of the best model : \")\n",
    "print(bestConfMaxMod6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning curves of each model with the best model : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titleLc1 = \"Learning curves Perceptron\"\n",
    "analyzer.plotLearningCurves(bestModel1.model, x, t, title=titleLc1)\n",
    "\n",
    "z=0\n",
    "for specific_tuple in list_tuple:\n",
    "    \n",
    "    if z == 0:\n",
    "        bestModel2 = bestModel2a\n",
    "    if z == 1:\n",
    "        bestModel2 = bestModel2b\n",
    "    if z == 2:\n",
    "        bestModel2 = bestModel2c\n",
    "    if z == 3:\n",
    "        bestModel2 = bestModel2d\n",
    "    \n",
    "    titleLc2 = \"Learning curves Multilayer Perceptron\" + str(specific_tuple)\n",
    "    analyzer.plotLearningCurves(bestModel2.model, x, t, title=titleLc2)\n",
    "    plt.show()\n",
    "    z= z+1\n",
    "    \n",
    "titleLc3 = \"Learning curves SVM with rbf\"\n",
    "analyzer.plotLearningCurves(bestModel3.model, x, t, title=titleLc3)\n",
    "plt.show()\n",
    "   \n",
    "titleLc4 = \"Learning curves Data tree classifier\"\n",
    "analyzer.plotLearningCurves(bestModel4.model, x, t, title=titleLc4)\n",
    "plt.show()\n",
    "\n",
    "titleLc5 = \"Learning curves Logistic Regression\"\n",
    "analyzer.plotLearningCurves(bestModel5.model, x, t, title=titleLc5)\n",
    "plt.show()\n",
    "\n",
    "titleLc6 = \"Learning curves Bagging\"\n",
    "analyzer.plotLearningCurves(bestModel6.model, x, t, title=titleLc6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters SVM with poly kernel :\n",
    "deg : 1 to 3\n",
    "C : 10^-3 to 10^3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minDeg = 1\n",
    "maxDeg = 4\n",
    "print(range(minDeg, maxDeg))\n",
    "bestDegMod7 = 1\n",
    "bestCMod7 = 1\n",
    "bestTestScore = float(\"inf\")\n",
    "\n",
    "for deg in range(minDeg, maxDeg):\n",
    "    model7 = Model.ModelSVM(gamma=\"auto\",  kernel=\"poly\", degree=1)\n",
    "    para_range = np.logspace(-3, 3, 7)\n",
    "    titleVC = \"Validation curves : SVM with degree \" + str(deg)\n",
    "    plt, test_scores_deg_means = analyzer.plotValidationCurve(model7.model, x, t, title=titleVC, param_name=\"C\",param_range=para_range, verbose=True, scaling=\"log\")\n",
    "    \n",
    "    bestInd = np.argmax(test_scores_deg_means)\n",
    "    print(bestInd)\n",
    "    \n",
    "    model7Reg = para_range[bestInd]\n",
    "    print(\"Best c for the degree \", deg, \" is : \",model7Reg)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    if test_scores_deg_means[bestInd] < bestTestScore:\n",
    "        bestTestScore\n",
    "        bestCMod7 = mode73Reg\n",
    "        bestDegMod7 = deg\n",
    "\n",
    "print(\"The best parameter are (deg, C) :\", bestDegMod7, bestCMod7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training model SVM with poly kernel : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters of the SVM model\n",
    "hyp1Mod7 = bestDegMod7\n",
    "hyp2Mod7 = bestCMod7\n",
    "print(\"Training with the parameters (deg, C) :\", hyp1Mod7, hyp2Mod7)\n",
    "\n",
    "bestAccuMod7 = 0\n",
    "bestConfMaxMod7 = 0\n",
    "bestModel7 =  0\n",
    "\n",
    "# Training\n",
    "accu = np.zeros(k)\n",
    "\n",
    "for i in range(k):\n",
    "    print(\"Training \", i + 1, \" model SVM...\")\n",
    "    md7 = Model.ModelSVM(gamma=\"auto\",  kernel=\"poly\", degree=hyp1Mod7, reg=hyp2Mod7, random_state=i)\n",
    "    md7.train(x_train, t_train)\n",
    "    predictions_test = np.array([md7.prediction(x) for x in x_test])\n",
    "\n",
    "    accu[i] = analyzer.accuracy(t_test, predictions_test)\n",
    "    \n",
    "    if accu[i] > bestAccuMod7:\n",
    "        bestAccuMod7 = accu[i]\n",
    "        bestModel7 = md7\n",
    "        bestConfMaxMod7 = analyzer.confusionMatrix(t_test, predictions_test)\n",
    "\n",
    "\n",
    "# Average accuracy and  std accuracy\n",
    "print(accu)\n",
    "accuMean = np.mean(accu)\n",
    "accuStd = np.std(accu)\n",
    "print(\"The average accuracy is : \", accuMean)\n",
    "print(\"The std accuracu is : \", accuStd)\n",
    "print(\"The best accuracy is : \", bestAccuMod7)\n",
    "print(\"The confusion matrix of the best model : \")\n",
    "print(bestConfMaxMod7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning curves SVM(poly):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titleLc7 = \"Learning curves SVM with poly\"\n",
    "analyzer.plotLearningCurves(bestModel7.model, x, t, titleLc7)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
